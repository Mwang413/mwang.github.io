{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries and define common helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "import json\n",
    "from pathlib import Path\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "import pyarrow as pa\n",
    "from pyarrow.json import read_json\n",
    "import pyarrow.parquet as pq\n",
    "import fastavro\n",
    "import pygeohash\n",
    "import snappy\n",
    "import jsonschema\n",
    "from jsonschema import validate\n",
    "from jsonschema.exceptions import ValidationError\n",
    "\n",
    "current_dir = Path(os.getcwd()).absolute()\n",
    "schema_dir = current_dir.joinpath('schemas')\n",
    "results_dir = current_dir.joinpath('results')\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def read_jsonl_data():\n",
    "    src_data_path = \"/home/jovyan/dsc650/data/processed/openflights/routes.jsonl.gz\"\n",
    "    with open(src_data_path, 'rb') as f_gz:\n",
    "        with gzip.open(f_gz, 'rb') as f:\n",
    "            records = [json.loads(line) for line in f.readlines()]\n",
    "\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = read_jsonl_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.a JSON Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 'the given file is valid')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def validate_jsonl_data(records):\n",
    "    schema_path = schema_dir.joinpath('routes-schema.json')\n",
    "    with open(schema_path) as f:\n",
    "        schema = json.load(f)\n",
    "        \n",
    "    with open(\"results/validation.csv\", 'w') as f:    \n",
    "        for i, record in enumerate(records):\n",
    "            try:\n",
    "                f.write(f\"{jsonschema.validate(record, schema=schema)}\")\n",
    "                pass\n",
    "            except ValidationError as e:\n",
    "                print (e)\n",
    "                pass\n",
    "            \n",
    "    message = \"the given file is valid\"\n",
    "    \n",
    "    return True, message\n",
    "            \n",
    "\n",
    "validate_jsonl_data(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.b Avro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'airline': {'airline_id': 410, 'name': 'Aerocondor', 'alias': 'ANA All Nippon Airways', 'iata': '2B', 'icao': 'ARD', 'callsign': 'AEROCONDOR', 'country': 'Portugal', 'active': True}, 'src_airport': {'airport_id': 2965, 'name': 'Sochi International Airport', 'city': 'Sochi', 'iata': 'AER', 'icao': 'URSS', 'latitude': 43.449902, 'longitude': 39.9566, 'timezone': 3.0, 'dst': 'N', 'tz_id': 'Europe/Moscow', 'type': 'airport', 'source': 'OurAirports'}, 'dst_airport': {'airport_id': 2990, 'name': 'Kazan International Airport', 'city': 'Kazan', 'iata': 'KZN', 'icao': 'UWKD', 'latitude': 55.606201171875, 'longitude': 49.278701782227, 'timezone': 3.0, 'dst': 'N', 'tz_id': 'Europe/Moscow', 'type': 'airport', 'source': 'OurAirports'}, 'codeshare': False, 'stops': 0, 'equipment': ['CR2']}\n",
      "{'airline': {'airline_id': 410, 'name': 'Aerocondor', 'alias': 'ANA All Nippon Airways', 'iata': '2B', 'icao': 'ARD', 'callsign': 'AEROCONDOR', 'country': 'Portugal', 'active': True}, 'src_airport': {'airport_id': 2966, 'name': 'Astrakhan Airport', 'city': 'Astrakhan', 'iata': 'ASF', 'icao': 'URWA', 'latitude': 46.2832984924, 'longitude': 48.0063018799, 'timezone': 4.0, 'dst': 'N', 'tz_id': 'Europe/Samara', 'type': 'airport', 'source': 'OurAirports'}, 'dst_airport': {'airport_id': 2990, 'name': 'Kazan International Airport', 'city': 'Kazan', 'iata': 'KZN', 'icao': 'UWKD', 'latitude': 55.606201171875, 'longitude': 49.278701782227, 'timezone': 3.0, 'dst': 'N', 'tz_id': 'Europe/Moscow', 'type': 'airport', 'source': 'OurAirports'}, 'codeshare': False, 'stops': 0, 'equipment': ['CR2']}\n",
      "{'airline': {'airline_id': 410, 'name': 'Aerocondor', 'alias': 'ANA All Nippon Airways', 'iata': '2B', 'icao': 'ARD', 'callsign': 'AEROCONDOR', 'country': 'Portugal', 'active': True}, 'src_airport': {'airport_id': 2966, 'name': 'Astrakhan Airport', 'city': 'Astrakhan', 'iata': 'ASF', 'icao': 'URWA', 'latitude': 46.2832984924, 'longitude': 48.0063018799, 'timezone': 4.0, 'dst': 'N', 'tz_id': 'Europe/Samara', 'type': 'airport', 'source': 'OurAirports'}, 'dst_airport': {'airport_id': 2962, 'name': 'Mineralnyye Vody Airport', 'city': 'Mineralnye Vody', 'iata': 'MRV', 'icao': 'URMM', 'latitude': 44.22510147094727, 'longitude': 43.08190155029297, 'timezone': 3.0, 'dst': 'N', 'tz_id': 'Europe/Moscow', 'type': 'airport', 'source': 'OurAirports'}, 'codeshare': False, 'stops': 0, 'equipment': ['CR2']}\n",
      "{'airline': {'airline_id': 410, 'name': 'Aerocondor', 'alias': 'ANA All Nippon Airways', 'iata': '2B', 'icao': 'ARD', 'callsign': 'AEROCONDOR', 'country': 'Portugal', 'active': True}, 'src_airport': {'airport_id': 2968, 'name': 'Chelyabinsk Balandino Airport', 'city': 'Chelyabinsk', 'iata': 'CEK', 'icao': 'USCC', 'latitude': 55.305801, 'longitude': 61.5033, 'timezone': 5.0, 'dst': 'N', 'tz_id': 'Asia/Yekaterinburg', 'type': 'airport', 'source': 'OurAirports'}, 'dst_airport': {'airport_id': 2990, 'name': 'Kazan International Airport', 'city': 'Kazan', 'iata': 'KZN', 'icao': 'UWKD', 'latitude': 55.606201171875, 'longitude': 49.278701782227, 'timezone': 3.0, 'dst': 'N', 'tz_id': 'Europe/Moscow', 'type': 'airport', 'source': 'OurAirports'}, 'codeshare': False, 'stops': 0, 'equipment': ['CR2']}\n",
      "{'airline': {'airline_id': 410, 'name': 'Aerocondor', 'alias': 'ANA All Nippon Airways', 'iata': '2B', 'icao': 'ARD', 'callsign': 'AEROCONDOR', 'country': 'Portugal', 'active': True}, 'src_airport': {'airport_id': 2968, 'name': 'Chelyabinsk Balandino Airport', 'city': 'Chelyabinsk', 'iata': 'CEK', 'icao': 'USCC', 'latitude': 55.305801, 'longitude': 61.5033, 'timezone': 5.0, 'dst': 'N', 'tz_id': 'Asia/Yekaterinburg', 'type': 'airport', 'source': 'OurAirports'}, 'dst_airport': {'airport_id': 4078, 'name': 'Tolmachevo Airport', 'city': 'Novosibirsk', 'iata': 'OVB', 'icao': 'UNNT', 'latitude': 55.012599945068, 'longitude': 82.650703430176, 'timezone': 7.0, 'dst': 'N', 'tz_id': 'Asia/Krasnoyarsk', 'type': 'airport', 'source': 'OurAirports'}, 'codeshare': False, 'stops': 0, 'equipment': ['CR2']}\n",
      "{'airline': {'airline_id': 410, 'name': 'Aerocondor', 'alias': 'ANA All Nippon Airways', 'iata': '2B', 'icao': 'ARD', 'callsign': 'AEROCONDOR', 'country': 'Portugal', 'active': True}, 'src_airport': {'airport_id': 4029, 'name': 'Domodedovo International Airport', 'city': 'Moscow', 'iata': 'DME', 'icao': 'UUDD', 'latitude': 55.40879821777344, 'longitude': 37.90629959106445, 'timezone': 3.0, 'dst': 'N', 'tz_id': 'Europe/Moscow', 'type': 'airport', 'source': 'OurAirports'}, 'dst_airport': {'airport_id': 2990, 'name': 'Kazan International Airport', 'city': 'Kazan', 'iata': 'KZN', 'icao': 'UWKD', 'latitude': 55.606201171875, 'longitude': 49.278701782227, 'timezone': 3.0, 'dst': 'N', 'tz_id': 'Europe/Moscow', 'type': 'airport', 'source': 'OurAirports'}, 'codeshare': False, 'stops': 0, 'equipment': ['CR2']}\n"
     ]
    }
   ],
   "source": [
    "from fastavro import writer, reader, parse_schema\n",
    "\n",
    "def create_avro_dataset(records):\n",
    "    schema_path = schema_dir.joinpath('routes.avsc')\n",
    "    data_path = results_dir.joinpath('routes.avro')\n",
    "\n",
    "    with open (schema_path, \"r\") as s:\n",
    "        schema_parsed = parse_schema(json.load(s))\n",
    "        \n",
    "    with open(data_path, \"wb\") as out:\n",
    "        writer(out, schema_parsed, records)\n",
    "        \n",
    "    with open(data_path, \"rb\") as fo:\n",
    "        i=0\n",
    "        for record in reader(fo):\n",
    "            i+=1\n",
    "            print (record)\n",
    "            if i > 5:\n",
    "                break\n",
    "    \n",
    "create_avro_dataset(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.c Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             airline  \\\n",
      "0  {'active': True, 'airline_id': 410, 'alias': '...   \n",
      "\n",
      "                                         src_airport  \\\n",
      "0  {'airport_id': 2965.0, 'altitude': 89.0, 'city...   \n",
      "\n",
      "                                         dst_airport  codeshare equipment  \n",
      "0  {'airport_id': 2990.0, 'altitude': 411.0, 'cit...      False     [CR2]  \n"
     ]
    }
   ],
   "source": [
    "def create_parquet_dataset():\n",
    "    src_data_path = 'data/processed/openflights/routes.jsonl.gz'\n",
    "    parquet_output_path = results_dir.joinpath('routes.parquet')\n",
    "    s3 = s3fs.S3FileSystem(\n",
    "        anon=True,\n",
    "        client_kwargs={\n",
    "            'endpoint_url': endpoint_url\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    with s3.open(src_data_path, 'rb') as f_gz:\n",
    "        with gzip.open(f_gz, 'rb') as f:\n",
    "            df = pd.read_json(f, lines=True)\n",
    "            table = pa.Table.from_pandas(df)\n",
    "            with open(parquet_output_path, \"wb\") as w:\n",
    "                pq.write_table(table, w)\n",
    "    \n",
    "    table2 = pq.read_table(parquet_output_path)\n",
    "    print(table2.to_pandas()[0:1]) \n",
    "            \n",
    "            ## TODO: Use Apache Arrow to create Parquet table and save the dataset\n",
    "\n",
    "create_parquet_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.d Protocol Buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\n\\x1e\\n\\x1a\\x08\\x9a\\x03\\x12\\nAerocondor\"\\x022B*\\x03ARD@\\x01 \\x00\\n\\x1e\\n\\x1a\\x08\\x9a\\x03\\x12\\nAerocondor\"\\x022B*\\x03ARD@\\x01 \\x00\\n\\x1e\\n\\x1a\\x08\\x9a\\x03\\x12\\nAerocondor\"\\x022B*\\x03ARD@\\x01 \\x00\\n\\x1e\\n\\x1a'\n"
     ]
    }
   ],
   "source": [
    "sys.path.insert(0, os.path.abspath('routes_pb2'))\n",
    "\n",
    "import routes_pb2\n",
    "\n",
    "def _airline_to_proto_obj(airline):\n",
    "    obj = routes_pb2.Airline()\n",
    "    if airline is None:\n",
    "        return None\n",
    "    if airline.get('airline_id') is None:\n",
    "        return None\n",
    "\n",
    "    obj.airline_id = airline.get('airline_id')\n",
    "    if airline.get('name'):\n",
    "        obj.name = airline.get('name')\n",
    "    if airline.get('city'):\n",
    "        obj.city = airline.get('city')\n",
    "    if airline.get('iata'):\n",
    "        obj.iata = airline.get('iata')\n",
    "    if airline.get('icao'):\n",
    "        obj.icao = airline.get('icao')\n",
    "    if airline.get('altitude'):\n",
    "        obj.altitude = airline.get('altitude')\n",
    "    if airline.get('timezone'):\n",
    "        obj.timezone = airline.get('timezone')\n",
    "    if airline.get('dst'):\n",
    "        obj.dst = airline.get('dst')\n",
    "    if airline.get('tz_id'):\n",
    "        obj.tz_id = airline.get('tz_id')\n",
    "    if airline.get('type'):\n",
    "        obj.type = airline.get('type')\n",
    "    if airline.get('source'):\n",
    "        obj.source = airline.get('source')\n",
    "    \n",
    "    if airline.get(\"latitude\"):\n",
    "        obj.latitude = airline.get('latitude')\n",
    "    if airline.get(\"longitude\"):\n",
    "        obj.longitude = airline.get('longitude')\n",
    "\n",
    "    if airline.get(\"active\") is not None:\n",
    "        obj.active = airline.get(\"active\")\n",
    "        \n",
    "    return obj\n",
    "\n",
    "\n",
    "def create_protobuf_dataset(records):\n",
    "    routes = routes_pb2.Routes()\n",
    "    for record in records:\n",
    "        route = routes_pb2.Route()\n",
    "        airline = _airline_to_proto_obj(record.get('airline', {}))\n",
    "        if airline:\n",
    "            route.airline.CopyFrom(airline)\n",
    "        src_airline = _airline_to_proto_obj(record.get('src_airline', {}))\n",
    "        route.codeshare = record[\"codeshare\"]\n",
    "        routes.route.append(route)\n",
    "\n",
    "    data_path = results_dir.joinpath('routes.pb')\n",
    "\n",
    "    with open(data_path, 'wb') as f:\n",
    "        f.write(routes.SerializeToString())\n",
    "        \n",
    "    compressed_path = results_dir.joinpath('routes.pb.snappy')\n",
    "    \n",
    "    with open(compressed_path, 'wb') as f:\n",
    "        f.write(snappy.compress(routes.SerializeToString()))\n",
    "    \n",
    "    with open (data_path, \"rb\") as f:\n",
    "        print(f.read(100))\n",
    "        \n",
    "    # I'm guessing this is fine???\n",
    "        \n",
    "        \n",
    "create_protobuf_dataset(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open (\"results/comparison.csv\", \"w\") as w:\n",
    "#     w.write(\"1\")\n",
    "df = pd.DataFrame([None])\n",
    "df[\"avro\"] = str(os.path.getsize(\"results/routes.avro\")/1024/1024)+\" MB\"\n",
    "df[\"parquet\"] = str(os.path.getsize(\"results/routes.parquet\")/1024/1024)+\" MB\"\n",
    "df[\"pb\"] = str(os.path.getsize(\"results/routes.pb\")/1024/1024)+\" MB\"\n",
    "df[\"snappy_pb\"] = str(os.path.getsize(\"results/routes.pb.snappy\")/1024/1024)+\" MB\"\n",
    "df = df[df.columns[1:]]\n",
    "df.to_csv(\"results/comparison.csv\",columns=[\"avro\",\"parquet\",\"pb\",\"snappy_pb\"],index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.a Simple Geohash Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 3.2.a\n",
    "def create_hash_dirs(records):\n",
    "    geoindex_dir = results_dir.joinpath('geoindex')\n",
    "    geoindex_dir.mkdir(exist_ok=True, parents=True)\n",
    "    hashes = []\n",
    "    for record in records:\n",
    "        src_airport = record.get('src_airport', {})\n",
    "        if src_airport:\n",
    "            latitude = src_airport.get('latitude')\n",
    "            longitude = src_airport.get('longitude')\n",
    "            if latitude and longitude:\n",
    "                hashes.append(pygeohash.encode(latitude, longitude))\n",
    "    hashes.sort()\n",
    "    three_letter = sorted(list(set([entry[:3] for entry in hashes])))\n",
    "    hash_index = {value: [] for value in three_letter}\n",
    "          \n",
    "    for record in records:\n",
    "        src_airport = record.get('src_airport', {})\n",
    "        if src_airport:\n",
    "            latitude = src_airport.get('latitude')\n",
    "            longitude = src_airport.get('longitude')\n",
    "            name = src_airport.get('name')\n",
    "            if latitude and longitude and name:\n",
    "                geohash = pygeohash.encode(latitude, longitude)\n",
    "                hash_index[geohash[:3]] = [geohash, name]\n",
    "    \n",
    "    \n",
    "    for key, values in hash_index.items():\n",
    "        output_dir = geoindex_dir.joinpath(str(key[:1])).joinpath(str(key[:2]))\n",
    "        output_dir.mkdir(exist_ok=True, parents=True)\n",
    "        output_path = output_dir.joinpath('{}.jsonl.gz'.format(key))\n",
    "        with gzip.open(output_path, 'w') as f:\n",
    "            json_output = '\\n'.join([json.dumps(value) for value in values])\n",
    "            f.write(json_output.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_hash_dirs(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.b Simple Search Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geohash: bzvpzpfrvzux\n",
      "No 2 letter matches, the coder is too busy(pronounciation: lay-zee), please try a different location...\n"
     ]
    }
   ],
   "source": [
    "def read_jsonl(airport_file):\n",
    "    with open(airport_file, 'rb') as f_gz:\n",
    "        with gzip.open(f_gz, 'rb') as f:\n",
    "            airport_info = [json.loads(line) for line in f.readlines()]\n",
    "    \n",
    "    return airport_info\n",
    "\n",
    "def airline_search(latitude, longitude):\n",
    "    geohash = pygeohash.encode(latitude, longitude)\n",
    "    first = geohash[0]\n",
    "    second = geohash[1]\n",
    "    third = geohash[2]\n",
    "    first_path= f\"results/geoindex/{geohash[0]}/{geohash[0:2]}\"\n",
    "    second_path = f\"{first_path}/{geohash[0:3]}.jsonl.gz\"\n",
    "    \n",
    "    print(\"geohash: \"+ geohash)\n",
    "    while True:\n",
    "        \n",
    "        if os.path.exists(second_path):\n",
    "#             print(\"second_path:\", second_path)\n",
    "            \n",
    "            if len(read_jsonl(second_path))>0:\n",
    "                airport_dict={}\n",
    "                if type(read_jsonl(second_path)[0]) != \"list\":\n",
    "                    airp_hash = read_jsonl(second_path)[0]\n",
    "                    name = read_jsonl(second_path)[1]\n",
    "                    dist = pygeohash.geohash_approximate_distance(geohash, airp_hash)\n",
    "                    airport_dict[f\"{dist}\"] = name\n",
    "                print(\"Closest airport is: \" + airport_dict.get(str(min([int(i) for i in airport_dict.keys()]))))\n",
    "                break\n",
    "            \n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "        else:\n",
    "            if os.path.exists(first_path) is not True:\n",
    "                print(\"No 2 letter matches, the coder is too busy(pronounciation: lay-zee), please try a different location...\")\n",
    "                break\n",
    "            else:\n",
    "                print(\"no 3 letter geohash match, getting 2 letter hash matches in\", first_path)\n",
    "    #             if len(read_jsonl(second_path))>0:\n",
    "\n",
    "                airport_dict= {}\n",
    "\n",
    "                for i in os.listdir(first_path):\n",
    "                    cur_airp = read_jsonl(first_path+ f\"/{i}\")\n",
    "\n",
    "                    if cur_airp:\n",
    "                        print(cur_airp)\n",
    "                        if type(cur_airp[0]) != \"list\": # to avoid files that contain more than 1 airport, not sure if necessary...\n",
    "                            airp_hash = cur_airp[0]\n",
    "                            print(airp_hash)\n",
    "                            name = cur_airp[1]\n",
    "                            dist = pygeohash.geohash_approximate_distance(geohash, airp_hash) # FOr some reason, all the distance is the same at this point\n",
    "                            print(dist)\n",
    "                            airport_dict[f\"{dist}\"] = name\n",
    "\n",
    "                print(airport_dict)\n",
    "\n",
    "                print(\"Closest airport is: \" + airport_dict.get(str(min([int(i) for i in airport_dict.keys()]))))\n",
    "            break\n",
    "\n",
    "    \n",
    "airline_search(134.142988, -138.90779)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
